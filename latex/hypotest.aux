\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {6}Hypothesis testing}{18}{section.6}}
\newlabel{sec:hypotest}{{6}{18}{Hypothesis testing}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Type-I and type-II errors}{18}{subsection.6.1}}
\newlabel{eqn:testsize}{{81}{18}{Type-I and type-II errors}{equation.6.81}{}}
\newlabel{eqn:power}{{82}{18}{Type-I and type-II errors}{equation.6.82}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Division of possibilities for the test statistic ($X$) into the yellow critical region $w$, and the blue region of acceptance $(\mathcal  {W}-w)$. The probabilities that $X$ falls into the critical region, under the null hypothesis and alternate hypothesis are $\alpha $ and $(1-\beta )$, respectively.}}{19}{figure.6}}
\newlabel{fig:htestregions}{{6}{19}{Division of possibilities for the test statistic ($X$) into the yellow critical region $w$, and the blue region of acceptance $(\mathcal {W}-w)$. The probabilities that $X$ falls into the critical region, under the null hypothesis and alternate hypothesis are $\alpha $ and $(1-\beta )$, respectively}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Distribution of $p$-values under the hypothesis that $\epsilon =0.9$. The error bars indicate the standard deviation of the a Poisson whose mean equals the number of observed entries in each bin.}}{20}{figure.7}}
\newlabel{fig:p0dist}{{7}{20}{Distribution of $p$-values under the hypothesis that $\epsilon =0.9$. The error bars indicate the standard deviation of the a Poisson whose mean equals the number of observed entries in each bin}{figure.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Likelihoods}{20}{subsection.6.2}}
\newlabel{eqn:likelihood}{{85}{21}{Likelihoods}{equation.6.85}{}}
\newlabel{eqn:likelihoodprod}{{86}{21}{Likelihoods}{equation.6.86}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Neyman-Pearson Lemma}{21}{subsection.6.3}}
\newlabel{eqn:nptestsize}{{87}{21}{Neyman-Pearson Lemma}{equation.6.87}{}}
\newlabel{eqn:nppower}{{88}{21}{Neyman-Pearson Lemma}{equation.6.88}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Nuisance parameters}{21}{subsection.6.4}}
\@writefile{toc}{\contentsline {paragraph}{Profiled likelihoods}{22}{section*.4}}
\newlabel{sec:marginalised}{{6.4}{22}{Marginalised posteriors}{section*.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Marginalised posteriors}{22}{section*.5}}
\newlabel{eqn:bayesmargin}{{95}{22}{Marginalised posteriors}{equation.6.95}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}A counting experiment}{23}{subsection.6.5}}
\newlabel{eqn:lambdanom}{{96}{23}{A counting experiment}{equation.6.96}{}}
\newlabel{eqn:lhcounting}{{98}{23}{A counting experiment}{equation.6.98}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Left: Twice negative log-likelihood function for the counting experiment vs $\mu $ and $\eta $. The red line shows the profiled value of the nuisance parameter at each value of $\mu $ $\mathaccentV {hat}05E{\eta }_{\mu }$. Right: the profiled log-likelihood function $q(\mu )$.}}{24}{figure.8}}
\newlabel{fig:profiledlikelihoodex_counting}{{8}{24}{Left: Twice negative log-likelihood function for the counting experiment vs $\mu $ and $\eta $. The red line shows the profiled value of the nuisance parameter at each value of $\mu $ $\hat {\eta }_{\mu }$. Right: the profiled log-likelihood function $q(\mu )$}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Left: Likelihood function multipltied by priors on $\mu $ and $\eta $ for the counting experiment vs $\mu $ and $\eta $. Right: the marginalised posterior function $P(\mu )$.}}{24}{figure.9}}
\newlabel{fig:marginalised_ex_counting}{{9}{24}{Left: Likelihood function multipltied by priors on $\mu $ and $\eta $ for the counting experiment vs $\mu $ and $\eta $. Right: the marginalised posterior function $P(\mu )$}{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Upper limits and common HEP test statistic}{25}{subsection.6.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Example distribution of $t_{\mu }$ for $\mu =8$ (left) and $\mu =15$ (right) . The vertical red line indicates the value of $t_{8}^{obs}$ and $t_{15}^{obs}$.}}{26}{figure.10}}
\newlabel{fig:tmu_example}{{10}{26}{Example distribution of $t_{\mu }$ for $\mu =8$ (left) and $\mu =15$ (right) . The vertical red line indicates the value of $t_{8}^{obs}$ and $t_{15}^{obs}$}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces  $p_{\mu }$ vs $\mu $. The horizontal red line lets us read off the value of $\mu _{\mathrm  {up}}$ at the 95\% confidence level, given our observation.}}{26}{figure.11}}
\newlabel{fig:pmu_example}{{11}{26}{$p_{\mu }$ vs $\mu $. The horizontal red line lets us read off the value of $\mu _{\mathrm {up}}$ at the 95\% confidence level, given our observation}{figure.11}{}}
\@setckpt{hypotest}{
\setcounter{page}{27}
\setcounter{equation}{109}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{2}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{section}{6}
\setcounter{subsection}{6}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{tcbbreakpart}{1}
\setcounter{tcblayer}{0}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{2}
\setcounter{bookmark@seq@number}{21}
\setcounter{lstnumber}{12}
\setcounter{section@level}{2}
\setcounter{lstlisting}{0}
}
