\section{Problems}

\subsection{Kolmogorov axioms}

Show that the definitions of \emph{frequentist} and \emph{Bayesian} probabilities given in the lectures satisfy the three Kolmogorov axioms. 

\subsection{No correlation does not mean independence}

In the lectures, we said that two random variables which are independent will have a zero correlation coefficient. 

\begin{enumerate}
    \item Show that two continuous random variables $X$ and $Y$, with $(X,Y)\sim f(X,Y)$ which are independent will have a 0 correlation coefficient. 
    \item Let $X$ be a continuous random variable symmetrically distributed around 0 with a density function $f(X)$. Let $Y=X^{2}$. Show that despite the fact that $Y$ and $X$ are clearly dependent, their correlation coefficient is 0. 
\end{enumerate}

\subsection{Cauchy distribution}

In the lectures, we showed how the sum of two Gaussian distributed random variables is itself Gaussian distributed. Suppose now that $X\sim \phi(X;0,1)$ and  $Y\sim \phi(Y;0,1)$ are independent random variables. Show that the distribution of $Z=\dfrac{X}{Y}$ is Cauchy, i.e that $p(Z) = \dfrac{1}{\pi(1+Z^2)}$.

\textbf{Hint:} You should start by deriving the marginal distribution formula for the ratio of two independent random variables. Careful that the case $Y=0$ will cause a problem, so split the marginal distribution into two cases, one for $Y>0$ and one for $Y<0$. The sum of these marginal distributions will be the total distribution. 

\subsection{Convergence to a Dirac-delta function}

Let $X_{n}\sim\phi(X;0,1/n)$ for each $n$. Show that $X_{n}$ \emph{converges in distribution} to a probability density function which is a Dirac delta function at 0 $\delta(0)$. 

\textbf{Hint:} To show this, show that for any $X<0$, $F_{n}(X)\rightarrow 0$, and for any $X>0$, $F_{n}(X)\rightarrow 1$, as $n\rightarrow \infty$.


\subsection{Normal approximation to a Poisson}

Show that the Poisson probability density distribution $P(k)=\dfrac{\lambda^{k}}{k!}e^{-\lambda}$ converges (in distribution) to a normal probability density distribution as $\lambda\rightarrow\infty$. What are the mean and variance of the normal distribution that it converges to?

\textbf{Hint:} Start by considering a ``standardized'' Poisson random variable $K=\dfrac{k-\lambda}{\sqrt{\lambda}}$.

\subsection{Phone call for Peter Higgs}

You are sat at home with your statistics problems staring at you from across the room, and rather than solving them, you decide to procrastinate by dialing random telephone numbers. You punch a mobile number in only to have Peter Higgs himself pick up at the other end. What is the probability of picking Professor Higgs' number out of all possible UK mobile numbers? Is this more or less likely than the discovery of the Higgs boson being an accident due to a large fluctuation of the background?

\textbf{Hint:} You can assume the Higgs discovery was at exactly 5$\sigma$. Convert this to a $p$-value using a one-sided test as explained in lectures. Also use the fact that all UK mobile numbers are 11 digit numbers starting with 07. 

\subsection{Coverage of Poisson intervals}
Consider a simple Poisson process $k\sim \frac{\lambda^{k}}{k!}e^{-\lambda}$. The mean of the Poisson is $\lambda$ and its variance is $\sqrt{\lambda}$. Often, particle physicists will use this fact to ``measure'' $\lambda$, after observing $k$ events as $\lambda=k\pm\sqrt{k}$ -- i.e, claiming the range $[k-\sqrt{k},k+\sqrt{k}]$ as the 68.3\% interval. 

\begin{itemize}
    \item Calculate the coverage of this method for $\lambda$ in the range $\lambda\in[0.1,3]$ in steps of 0.1.
    \item Instead devise a method using a Neyman construction for the 68.3\% interval and calculate the coverage of that method in the same range.
\end{itemize}    

How do the coverage properties of the two methods to obtain a 68.3\% confidence interval compare?


\subsection{Maximum likelihood and intervals for exponential decay}

Suppose we want to determine the lifetime ($\tau$) of an unstable particle. The probability for this particle to decay at time $t$ is given by, 
\begin{equation}
    p(t) = N(\tau)e^{-t/\tau}
\end{equation}
Suppose then that in the lab, we've made measurements of the decay times (say by measuring the times at which we detect one or more decay products from a source), and have the following observed decay times; $t=$7.44, 4.13, 26.85, 1.42, 3.46, 2.68, 4.1, 4.04, 7.9 and 12.03 in ns.

\begin{enumerate}
\item Normalise the probability density function (i.e what is $N(\tau)$?)

\item What does the log-likelihood function look like for this dataset? Use your favourite plotting program to plot it as a function of $\tau$.  

\item What is the maximum likelihood (minimum negative log-likelihood) estimate for $\tau$? \textbf{Hint}: You can calculate this analytically or numerically (or even better, do both and compare answers).

\item Using Wilkes' theorem, estimate the 68.3\% confidence interval for $\tau$.

\item Derive a 68\% confidence interval for $\tau$ using the Neyman construction approach. You can use the profile likelihood ratio (as we did in lectures) as the test statistic for this. 

\end{enumerate}

