{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4670db7e-9da8-4fca-a26d-e3906e96ee1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Frequentist Upper limits  \n",
    "\n",
    "Let's calculate the upper limit for our simple example counting experiment using a MC method. The first thing is to decide how we are going to generate pseudo-experiments (toys) to determine $f(t_{\\mu}|H(\\mu))$. We have again encountered the problem that $H(\\mu)$ is defined only for a fixed choice of the nuisance parameters $\\eta$. \n",
    "\n",
    "Once again, we'll turn to our choice of the *best* values, meaning we will pick those which minimises $q(\\mu,\\eta)$ for a given value of $\\mu$ given our observed data.\n",
    "\n",
    "For each toy, we want to generate a random value of the observation $n'$, given $\\mu,\\hat{\\eta}_{\\mu}$ and a value of $\\eta'$ which represents the random outcome for $\\eta$ our luminosity measurement - remember, in the frequentist view, the value that we obtained can also be interpreted as a random variable with a known distribution $\\eta{^{\\prime}}\\sim\\phi(\\hat{\\eta}_{\\mu},1)$, our observed data then becomes $(n^{\\prime},\\eta^{\\prime})$. We need to modify the likelihood function for each toy slightly to read, \n",
    "\n",
    "$$\n",
    "    L(\\alpha,\\eta) = L(n^{\\prime},\\eta^{\\prime}) = \\lambda(\\mu,\\eta)^{n\\prime}e^{-\\lambda}\\cdot e^{-\\frac{1}{2}(\\eta-\\eta^{\\prime})^{2}},\n",
    "$$\n",
    "\n",
    "For each toy, we can then calculate $t_{\\mu}$ using this data in the likelihood function and histogram the results. Note that for each toy, we will find different values of $\\hat{\\mu}$ and $\\hat{\\eta}_{\\mu}$! \n",
    "\n",
    "We've seen many of the functions we need before but let's copy the ones we need here and modify them to account for the fact that $\\eta^{\\prime}\\neq 0$ necessarily..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f4e5c-78cf-469c-9d0a-7c96708ecf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "from counting_model_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052feb9a-52a9-437f-a3b3-72bbe9df4e4b",
   "metadata": {},
   "source": [
    "Since we need to know the global minimum, we'll write a function do find that for us. \n",
    "\n",
    "Rather than writing the derivatives in  terms of $\\mu$ and using a 2D method, we will rely on the `minimize` function from the `scipy.optimize` package to find the minimum point in 2D for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d54f50-a86b-4b64-b88e-d9fab0e7e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "    \n",
    "def global_min(n_p,eta_p):\n",
    "    init = [1.,-1.]\n",
    "    bounds=[[0,20],[-5,5]]\n",
    "    res = minimize(q_formin,init,args=[n_p,eta_p],bounds=bounds)\n",
    "    return res.fun,res.x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49482e3a-fda9-4fa6-9076-17548c21dd38",
   "metadata": {},
   "source": [
    "Now we are ready to define the test statistic. The typical  one we use in HEP is \n",
    "\n",
    "$$\n",
    "    t_{\\mu} = \\begin{cases}\n",
    "                q(\\mu,\\hat{\\eta}_{\\mu})-q(\\hat{0},\\hat{\\eta}_{0})    & \\hat{\\mu} < 0 \\\\\n",
    "                q(\\mu,\\hat{\\eta}_{\\mu})-q(\\hat{\\mu},\\hat{\\eta})    & \\hat{\\mu} \\in (0,\\mu] \\\\\n",
    "                0               & \\hat{\\mu}>\\mu,\n",
    "                \\end{cases}\n",
    "$$\n",
    "\n",
    "so let's define a function for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d5cd06-df96-44b7-a9b6-a71269c76765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate test statistic\n",
    "def tmu(n_p,eta_p,mu):\n",
    "  q_value        = q(mu,profiled_eta(n_p,eta_p,mu),n_p,eta_p)\n",
    "  q_min,mu_min   = global_min(n_p,eta_p)\n",
    "  #print(\"toy\",mu,n_p,eta_p,q_value, q_min,mu_min, q_value-q_min)\n",
    "  if mu_min < 0     : return q_value-q(n_p,eta_p,0,profiled_eta(n_p,eta_p,0))\n",
    "  elif mu_min <= mu : return q_value-q_min\n",
    "  else              : return 0\n",
    "\n",
    "vectorized_tmu = numpy.vectorize(tmu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcfde76-7625-4ade-afa8-73437efa3dad",
   "metadata": {},
   "source": [
    "We'll need to determine the test-statistic distribution for each value of the parameter of interest ($\\mu$) so again, let's define a function for that.   \n",
    "\n",
    "The function below returns the distribution of the test statistic at a specific value of $\\mu$ and, when provided with the observed value, will calculate the $p$-value\n",
    "\n",
    "$$\n",
    "    p_{\\mu} = \\int_{t^{\\mathrm{obs}}_{\\mu}}^{+\\infty} f(t_{\\mu}|H(\\mu))dt_{\\mu}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40153090-7791-407e-80b0-7d618a949d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_tmu(mu,t_obs):\n",
    "  # find the best (profiled) nuisance parameter values for the data (n,0)\n",
    "  eta_profiled = profiled_eta(n,0,mu)\n",
    "  ntoys = 1000\n",
    "  toy_n   = numpy.random.poisson(lamb(mu,eta_profiled),size=ntoys)\n",
    "  toy_eta = numpy.random.normal(eta_profiled,1,size=ntoys)\n",
    "  #tmu_dist = [tmu(n_p,eta_p,mu) for n_p,eta_p in zip(toy_n,toy_eta)]\n",
    "  tmu_dist = vectorized_tmu(toy_n,toy_eta,mu)\n",
    "  return tmu_dist, float(len(list(filter(lambda tm: tm > t_obs,tmu_dist))))/len(tmu_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2284f274-58c8-4602-b588-3bc7f3013613",
   "metadata": {},
   "source": [
    "As an example, we'll show the distribution for $\\mu=8$ and $\\mu=15$ and calculate $p_{8}$ and $p_{15}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53633a2a-4a9f-455b-bbd4-3577fc77aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_obs8  = tmu(n,0,8)\n",
    "t_obs15 = tmu(n,0,15)\n",
    "\n",
    "tmu_toys8,pval8   = histo_tmu(8,t_obs8)\n",
    "tmu_toys15,pval15 = histo_tmu(15,t_obs15)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(14,6))\n",
    "\n",
    "ax1.hist(tmu_toys8,density=True,color='black',histtype='step')\n",
    "ax1.plot([t_obs8,t_obs8],[0,0.5],color='red')\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_xlabel(\"$t_{%.1f}$\"%8)\n",
    "ax1.set_ylabel(\"$f(t_{%.1f}|H(%.1f)$\"%(8,8))\n",
    "\n",
    "ax2.hist(tmu_toys15,density=True,color='black',histtype='step')\n",
    "ax2.plot([t_obs15,t_obs15],[0,0.5],color='red')\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_xlabel(\"$t_{%.1f}$\"%15)\n",
    "ax2.set_ylabel(\"$f(t_{%.1f}|H(%.1f)$\"%(15,15))\n",
    "\n",
    "print(\"p_8 = \",pval8)\n",
    "print(\"p_15 = \",pval15)\n",
    "plt.show()\n",
    "plt.savefig(\"p10.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb63b8-4b18-414d-94f7-38709e68c418",
   "metadata": {},
   "source": [
    "The red lines indicates the observed value of the test-statistic. In the case that $\\mu=8$ the $p$-value is larger than 0.05, while for $\\mu=15$, the $p$-value is smaller than 0.05. We know therefore that the uppre limit lies somewhere between these two values.  \n",
    "\n",
    "Now let's try a  range of values to search for the largest value of $\\mu$ for which $p_{\\mu}$>0.05. This value $\\mu_{up}$ is our 95% CL upper limit on $\\mu$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f65911-1f69-41d9-b3f6-aa868c6f34ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mu_list = []\n",
    "mu_test_list = numpy.arange(9,15,1)\n",
    "\n",
    "for mu_test in mu_test_list :\n",
    "  t_obs = tmu(n,0,mu_test)\n",
    "  tmu_toys,pval = histo_tmu(mu_test,t_obs)\n",
    "  p_mu_list.append(pval)\n",
    "\n",
    "# from the graph, we can read of upper limits (eg for 95\\% CL)\n",
    "plt.plot(mu_test_list,p_mu_list,color='black',marker=\"o\")\n",
    "plt.plot([8,15],[0.05,0.05],color='red')\n",
    "\n",
    "plt.xlabel(\"$\\mu$\")\n",
    "plt.ylabel(\"$p_{\\mu}$\")\n",
    "plt.show()\n",
    "plt.savefig(\"scan_pmu.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b04a51-e1af-4634-82e8-e582eea895d8",
   "metadata": {},
   "source": [
    "We can find the upper limit by reading off where the black line crosses the red horizontal line at 0.05. In our simple counting experiment the 95% CL upper limit is $\\mu_{up}\\sim 11$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec0676-29d5-4a02-bbec-16e1767cd824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
