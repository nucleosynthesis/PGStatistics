{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7852e1",
   "metadata": {},
   "source": [
    "# Frequentist intervals\n",
    "\n",
    "In lectures we learned a construction of frequentist intervals (the Neyman construction) that is designed to acheive a good coverage. In this notebook, we're going to apply this method to our simple counting experiment and calculate a frequentist interval, and calculate  the coverage of the intervals. We'll also compare to the interval one would get from applying Wilks' theorem. \n",
    "\n",
    "## Neyman intervals with profiled likelihood\n",
    "\n",
    "We'll start with the Neyman construction for our interval. In this case, we'll calculate a 68% interval (commonly refered to as a 1$\\sigma$ interval).\n",
    "\n",
    "First, let's define our counting experiment model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f5f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# define the model for the counting experiment\n",
    "sigma_TH = 0.01\n",
    "A   = 0.5\n",
    "eff = 0.9\n",
    "l   = 100.\n",
    "k   = 0.1\n",
    "n   = 2\n",
    "\n",
    "# Poisson mean\n",
    "def lamb(mu,eta):\n",
    "  return mu*eff*A*l*((1+k)**eta)*sigma_TH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e100170f",
   "metadata": {},
   "source": [
    "We need to define our test-statistic. We will use the one based on the profiled likelihood ratio, i.e \n",
    "\n",
    "$$\n",
    "\\zeta_{\\mu} = q(\\mu,\\eta_{\\mu}) - q(\\hat{\\mu},\\hat{\\eta})\n",
    "$$\n",
    "if $\\hat{\\mu}\\geq 0$ or, \n",
    "$$\n",
    "\\zeta_{\\mu} = q(\\mu,\\eta_{\\mu}) - q(0,\\eta_{0})\n",
    "$$\n",
    "otherwise.\n",
    "\n",
    "We can define each of these terms as functions to help us keep track.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define q, and q unconstrained and constrained functions\n",
    "def q(mu,eta,np,eta_p):\n",
    "  la = lamb(mu,eta)\n",
    "  if np==0: return (eta-eta_p)*(eta-eta_p) + 2*la\n",
    "  elif la<=0: return 99999\n",
    "  else: return (eta-eta_p)*(eta-eta_p) + 2*la -2*np*numpy.log(la)\n",
    "\n",
    "def q_unconstrained(x, args):\n",
    "  mu, eta = x[0], x[1]\n",
    "  np, eta_p = args[0], args[1]\n",
    "  return q(mu,eta,np,eta_p)\n",
    "\n",
    "def q_constrained(x, args):\n",
    "  eta=x[0]\n",
    "  mu, np, eta_p = args[0], args[1], args[2]\n",
    "  return q(mu,eta,np,eta_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5dc301",
   "metadata": {},
   "source": [
    "And some functions to find the profiled values of $\\mu$ and $\\eta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the minimisation routines\n",
    "def profiled_eta(mu, np, eta_p):\n",
    "  init_params = [-3.0]\n",
    "  bounds = [(-5,5)]\n",
    "  res = minimize(q_constrained,init_params,args=[mu,np,eta_p],bounds=bounds)\n",
    "  return res.x[0]\n",
    "\n",
    "def global_min(np,eta_p):\n",
    "  init_params = [0.1,-3.]\n",
    "  bounds = [(-1,50),(-5,5)]\n",
    "  mle = minimize(q_unconstrained,init_params,args=[np,eta_p],bounds=bounds)\n",
    "  return mle.fun,mle.x[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2591656",
   "metadata": {},
   "source": [
    "Finally, we have all of the pieces to define our test-statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d23fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate test statistic\n",
    "@numpy.vectorize\n",
    "def zetamu(np,eta_p,mu):\n",
    "  q_value        = q(mu,profiled_eta(mu,np,eta_p),np,eta_p)\n",
    "  q_min,mu_min   = global_min(np,eta_p)\n",
    "  if mu_min < 0     : return q_value-q(0,profiled_eta(0,np,eta_p),np,eta_p)\n",
    "  else              : return q_value-q_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f313f43f",
   "metadata": {},
   "source": [
    "Remember, we want to know, for each value of our parameter of interest ($\\mu$), the part of the test-statistic distribution that contains 68% of possible outcomes of the test-statistic. \n",
    "\n",
    "For our test-statistic, this is the same as finding a single value of the test-statistic (call it $\\zeta_{68}$) for which 68% of  $\\zeta$ values are below. Remember, this is specified for each value of $\\mu$. We'll define a function to generate toys so that we can determine the distribution of $\\zeta$ and  $\\zeta_{68}$. \n",
    "\n",
    "Notice that our toys consist of pairs of observations. One  is a random value of the observed  number of events $n$, and the other is a *observed* value of $\\eta^{\\prime}$. Usually this value is taken to be 0 but since it is too a random variable, it has a distribution. In HEP, we typically think of this as representing other measurements that we could have made for the parameter $\\eta$. \n",
    "\n",
    "We need to choose a pdf to generate these $\\eta^{\\prime}$ from. Of course it should be a normal distribution as that is the term in the likelihood. We need a central value for this normal distribution and the usual convention is to use the profiled value of $\\eta=\\eta_{mu}$ - i.e it will be a different value for each $\\mu$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a set of heights for each true value of mu\n",
    "# for each value, we would mark on where 68% of the distribution lives\n",
    "def histo_zetamu(mu):\n",
    "  # find the best (profiled) nuisance parameter values for the data (n,0)\n",
    "  eta_profiled = profiled_eta(mu,n,0)\n",
    "  ntoys = 5000\n",
    "  toy_n   = numpy.random.poisson(lamb(mu,eta_profiled),size=ntoys)\n",
    "  toy_eta = numpy.random.normal(eta_profiled,1,size=ntoys)\n",
    "  zetamu_dist = zetamu(toy_n,toy_eta,mu)\n",
    "  #zetamu_dist = [zetamu(np,eta_p,mu) for np,eta_p in zip(toy_n,toy_eta)]\n",
    "  zetamu_dist.sort() ; zeta_68 = zetamu_dist[int(ntoys*0.68)]\n",
    "  return zetamu_dist, zeta_68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f2773f",
   "metadata": {},
   "source": [
    "Let's look at the distribution for a single  value of $\\mu=2$. We'll print out the value of $\\zeta_{68}$ and the  value of  $\\zeta$ using the observed values of $n=2$ and $\\eta^{\\prime}=0$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeta_obs_2 = zetamu(n,0,2)\n",
    "\n",
    "distribution_2, zeta_68_2 =  histo_zetamu(2)\n",
    "plt.hist(distribution_2,bins=20)\n",
    "plt.xlabel(\"$\\zeta_{2}$\")\n",
    "plt.show()\n",
    "\n",
    "print(\"zeta_68=\",zeta_68_2)\n",
    "print(\"zeta_obs=\",zeta_obs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8088567",
   "metadata": {},
   "source": [
    "In this case, the observed value `zeta_obs` is less  than `zeta_68`. This means that the observed value is contained in the part of the distribution that contains 68% of the outcome! So we would accept this point ($\\mu=2$) into our 68% interval. \n",
    "\n",
    "Now let's repeat for a range of $\\mu$ values and report the full interval (i.e the range of points we accept). Note that this takes a little while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c860a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_range   = numpy.arange(0.1,10,0.2)\n",
    "zeta_range = numpy.arange(0.1,10,0.2)\n",
    "zeta_obs_vals = []\n",
    "zeta_68_vals  = []\n",
    "mu_interval = []\n",
    "densities = []\n",
    "\n",
    "for mu_test in mu_range:\n",
    "  zeta_obs = zetamu(n,0,mu_test)\n",
    "  zetamu_toys,zeta_68 = histo_zetamu(mu_test)\n",
    "\n",
    "  # we're also keeping a record of all the distributions\n",
    "  density_vals = plt.hist(zetamu_toys,density=True,bins=zeta_range)\n",
    "  densities.append(density_vals[0])\n",
    "\n",
    "  zeta_68_vals.append(zeta_68)\n",
    "  zeta_obs_vals.append(zeta_obs)\n",
    "  if zeta_obs < zeta_68 : mu_interval.append(mu_test)\n",
    "\n",
    "plt.clf()\n",
    "# Print out the results\n",
    "mu_l, mu_u = min(mu_interval),max(mu_interval)\n",
    "mu_hat = global_min(n,0)[1]\n",
    "print(\"interval -> (%.2f,%.2f)\"%(mu_l,mu_u),\", mu = %.2f + %.2f -%.2f \"%(mu_hat,mu_u-mu_hat,mu_hat-mu_l))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7629503",
   "metadata": {},
   "source": [
    "We can plot the distribution of $\\zeta_{\\mu}$ for each of our $\\mu$ values that we tested. The colour map below shows the density of our test-statistic disribution. We also can overlay the values of $\\zeta_{68}$ that we determined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0596c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = numpy.meshgrid(zeta_range,mu_range)\n",
    "c = plt.pcolor(X,Y,densities, \\\n",
    "    norm=LogNorm(vmin=0.001, vmax=2.0))\n",
    "plt.colorbar(c)\n",
    "plt.plot(zeta_obs_vals,mu_range,color='black',linewidth=3)\n",
    "plt.plot(zeta_68_vals,mu_range,color='red',linewidth=3)\n",
    "plt.xlabel(\"$\\zeta_{\\mu}$\")\n",
    "plt.ylabel(\"$\\\\mu$\")\n",
    "plt.title(\"$f(\\zeta_{\\mu}|H(\\mu))$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da7b2e4",
   "metadata": {},
   "source": [
    "You can see some odd structures here at small values of $\\mu$, that seem to smooth out at larger values. Also the value of  $\\zeta_{68}$ seems to settle down at larger values. This will be important for our next topic on coverage and Wilks'  theorem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a33c1a",
   "metadata": {},
   "source": [
    "## Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b6488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
